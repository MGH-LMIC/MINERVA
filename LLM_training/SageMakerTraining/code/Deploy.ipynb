{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cda1a1a",
   "metadata": {},
   "source": [
    "### Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "id": "572a3e3e",
   "metadata": {},
   "source": [
    "!pip install -U sagemaker\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f69179f3",
   "metadata": {},
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri, HuggingFace\n",
    "\n",
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "role"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff6e2591",
   "metadata": {},
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "############## Final Deployment #################\n",
    "#to_deploy = 'biomistralFIN-3class-k0-2024-04-30-23-07-32-592'\n",
    "#to_deploy = 'biomistralFINRAG-3class-k0-2024-05-01-14-54-54-877'\n",
    "to_deploy = 'biomistralFINLLM-3class-k0-2024-05-01-14-51-44-260'\n",
    "#to_deploy = 'biomistralFINALL-3class-k0-2024-05-01-14-45-16-880'\n",
    "\n",
    "print('Model to deploy: {}'.format(to_deploy))\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'train_aws.py',    # train script\n",
    "    source_dir           = 'scripts',      # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.g5.12xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    max_run              = 2*24*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    #base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.37',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.0',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    #hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = { \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\" }, # set env variable to cache models in /tmp\n",
    "    disable_output_compression = True         # not compress output to save training time and cost\n",
    ").attach(to_deploy)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "92bfb45c",
   "metadata": {},
   "source": [
    "get_huggingface_llm_image_uri(\"huggingface\",version=\"1.4\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "156e707e",
   "metadata": {},
   "source": [
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "\t'HF_MODEL_ID': '/opt/ml/model',#'salangarica/finetune-mistral-DA', #'salangarica/finetune-mistral-DA',\n",
    "\t'SM_NUM_GPUS': json.dumps(1),\n",
    "    'MAX_INPUT_LENGTH': json.dumps(3500),  # Max length of input text\n",
    "    'MAX_TOTAL_TOKENS': json.dumps(4000),\n",
    "    'HF_TASK':'text-generation',\n",
    "    #'HF_MODEL_REVISION':'23486089ab7ba741b34adc69ab7555885f8abe71',\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    image_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"1.4\"), #version=\"1.1.0\"\n",
    "    env=hub,                                                # configuration for loading model from Hub\n",
    "    model_data=huggingface_estimator.model_data,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1,\n",
    "\tinstance_type=\"ml.g5.2xlarge\",\n",
    "\tcontainer_startup_health_check_timeout=300,\n",
    "  )\n",
    "  \n",
    "# send request\n",
    "predictor.predict({\n",
    "\t\"inputs\": \"<|system|>\\nYou are a pirate chatbot who always responds with Arr!</s>\\n<|user|>\\nThere's a llama on my lawn, how can I get rid of him?</s>\\n<|assistant|>\\n\",\n",
    "})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b8d2f988",
   "metadata": {},
   "source": [
    "predictor.endpoint_name"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f608a888",
   "metadata": {},
   "source": [
    "predictor.predict({\n",
    "\t\"inputs\": \"\"\"<s>[INST] You are an expert microbiologist who given an excerpt from a research paper can easily \n",
    "identify the type of relation between a microbe and a disease. Doesn't create new information, but is completely faithful to the information provided, and always gives concise answers.\n",
    "Given the following meaning of the labels, answer the following question with the appropiate label.\n",
    "positive: This type is used to annotate microbe-disease entity pairs with positive correlation, such as microbe will cause or aggravate the disease, the microbe will increase when disease occurs.\n",
    "negative: This type is used to annotate microbe-disease entity pairs that have a negative correlation, such as microbe can be a treatment for a disease, or microbe will decrease when disease occurs. \n",
    "na: This type is used when the relation between a microbe and a disease is not clear from the context or there is no relation. In other words, use this label if the relation is not positive and not negative.\n",
    "\n",
    "Based on the above description, evidence is as follows: \n",
    "E.coli is positively correlated with diabetes but not with pneumonia\n",
    "\n",
    "What is the relationship between E.coli and diabetes?\n",
    " [/INST]\"\"\"\n",
    "})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eb025f88",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
